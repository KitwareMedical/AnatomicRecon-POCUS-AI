{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2021-05-31_09-29-34\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"SagittalSpineSegmentationStudy\"\n",
    "\n",
    "# Update this folder name for your computer\n",
    "\n",
    "local_data_folder = r\"c:\\Data\\SagittalSpineSegmentationStudy\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.00001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 10\n",
    "WCE_weights = np.array([0.1, 0.9])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "limit_validation_rounds = -1\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "\n",
    "# roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01]\n",
    "# limit_validation_rounds = 1\n",
    "# num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import sample\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from pytorch_unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what data to download\n",
    "\n",
    "girder_api_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "training_ultrasound_ids = [\n",
    "    \"5da9e5c0d9e6a3be02d012b4\",\n",
    "    \"5da9e5c7d9e6a3be02d012c6\",\n",
    "    \"5da9e5c2d9e6a3be02d012b7\",\n",
    "    \"5da9e5c3d9e6a3be02d012ba\",\n",
    "    \"5da9e5c8d9e6a3be02d012c9\",\n",
    "    \"5da9e5c5d9e6a3be02d012c0\",\n",
    "    \"5da9e5c6d9e6a3be02d012c3\",\n",
    "    \"5da9e5c4d9e6a3be02d012bd\"\n",
    "]\n",
    "\n",
    "training_ultrasound_filenames = [\n",
    "    \"q000_ultrasound.npy\",\n",
    "    \"q001_ultrasound.npy\",\n",
    "    \"q002_ultrasound.npy\",\n",
    "    \"q003_ultrasound.npy\",\n",
    "    \"q004_ultrasound.npy\",\n",
    "    \"q005_ultrasound.npy\",\n",
    "    \"q006_ultrasound.npy\",\n",
    "    \"q007_ultrasound.npy\"\n",
    "]\n",
    "\n",
    "training_segmentation_ids = [\n",
    "    \"5da9e5c8d9e6a3be02d012cc\",\n",
    "    \"5da9e5ccd9e6a3be02d012de\",\n",
    "    \"5da9e5c9d9e6a3be02d012cf\",\n",
    "    \"5da9e5cad9e6a3be02d012d2\",\n",
    "    \"5da9e5cdd9e6a3be02d012e1\",\n",
    "    \"5da9e5cbd9e6a3be02d012d8\",\n",
    "    \"5da9e5cbd9e6a3be02d012db\",\n",
    "    \"5da9e5cad9e6a3be02d012d5\"\n",
    "]\n",
    "\n",
    "training_segmentation_filenames = [\n",
    "    \"q000_segmentation.npy\",\n",
    "    \"q001_segmentation.npy\",\n",
    "    \"q002_segmentation.npy\",\n",
    "    \"q003_segmentation.npy\",\n",
    "    \"q004_segmentation.npy\",\n",
    "    \"q005_segmentation.npy\",\n",
    "    \"q006_segmentation.npy\",\n",
    "    \"q007_segmentation.npy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These subfolders will be created/populated in the data folder\n",
    "\n",
    "data_arrays_folder    = \"DataArrays\"\n",
    "notebooks_save_folder = \"SavedNotebooks\"\n",
    "results_save_folder   = \"SavedResults\"\n",
    "models_save_folder    = \"SavedModels\"\n",
    "val_data_folder       = \"PredictionsValidation\"\n",
    "\n",
    "data_arrays_fullpath = os.path.join(local_data_folder, data_arrays_folder)\n",
    "notebooks_save_fullpath = os.path.join(local_data_folder, notebooks_save_folder)\n",
    "results_save_fullpath = os.path.join(local_data_folder, results_save_folder)\n",
    "models_save_fullpath = os.path.join(local_data_folder, models_save_folder)\n",
    "val_data_fullpath = os.path.join(local_data_folder, val_data_folder)\n",
    "\n",
    "if not os.path.exists(data_arrays_fullpath):\n",
    "    os.makedirs(data_arrays_fullpath)\n",
    "    print(\"Created folder: {}\".format(data_arrays_fullpath))\n",
    "\n",
    "if not os.path.exists(notebooks_save_fullpath):\n",
    "    os.makedirs(notebooks_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(notebooks_save_fullpath))\n",
    "\n",
    "if not os.path.exists(results_save_fullpath):\n",
    "    os.makedirs(results_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(results_save_fullpath))\n",
    "\n",
    "if not os.path.exists(models_save_fullpath):\n",
    "    os.makedirs(models_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(models_save_fullpath))\n",
    "\n",
    "if not os.path.exists(val_data_fullpath):\n",
    "    os.makedirs(val_data_fullpath)\n",
    "    print(\"Created folder: {}\".format(val_data_fullpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training files ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67aee63316af4c2088ac65be69b97f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total download time: 0:00:00.017018\n"
     ]
    }
   ],
   "source": [
    "# Download data from Girder\n",
    "\n",
    "time_download_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Downloading training files ...\")\n",
    "\n",
    "# Setting up number of validation rounds\n",
    "\n",
    "n_files = len(training_ultrasound_ids)\n",
    "if limit_validation_rounds > 0:\n",
    "    num_validation_rounds = min(n_files, limit_validation_rounds)\n",
    "else:\n",
    "    num_validation_rounds = n_files\n",
    "\n",
    "# Preparing progress bar\n",
    "\n",
    "f = IntProgress(min=0, max=n_files*2)\n",
    "display(f)\n",
    "\n",
    "# Downloading files\n",
    "\n",
    "gclient = girder_client.GirderClient(apiUrl=girder_api_url)\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    if not os.path.exists(ultrasound_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(ultrasound_fullname))\n",
    "        gclient.downloadFile(training_ultrasound_ids[i], ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "    if not os.path.exists(segmentation_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(segmentation_fullname))\n",
    "        gclient.downloadFile(training_segmentation_ids[i], segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "\n",
    "time_download_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal download time: {}\".format(time_download_stop - time_download_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff755acd3a174457bce915bb19f7c757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time to load from files: 0:00:00.506314\n"
     ]
    }
   ],
   "source": [
    "# Read data into numpy arrays\n",
    "\n",
    "ultrasound_arrays = []\n",
    "segmentation_arrays = []\n",
    "\n",
    "f = IntProgress(min=0, max=n_files * 2)\n",
    "display(f)\n",
    "\n",
    "time_start = datetime.datetime.now()\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "\n",
    "    ultrasound_data = np.load(ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_data = np.load(segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "    \n",
    "    ultrasound_arrays.append(ultrasound_data)\n",
    "    segmentation_arrays.append(segmentation_data)\n",
    "\n",
    "time_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal time to load from files: {}\".format(time_stop - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Try to fix \"failed to get a convolution algorithm\" error\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# This didn't work\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# This worked for me --Nick\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2021-05-26_23-51-14\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    500\n",
      "Step size maximum:   0.02\n",
      "Step size decay:     3.998e-05\n",
      "Batch size:          128\n",
      "Regularization rate: 0.0001\n",
      "\n",
      "Saving validation predictions in: c:\\Data\\SagittalSpineSegmentationStudy\\PredictionsValidation\n",
      "Saving models in:                 c:\\Data\\SagittalSpineSegmentationStudy\\SavedModels\n",
      "\n",
      "*** Leave-one-out round # 7\n",
      "\n",
      "Training on 2844 images, validating on 446 images...\n",
      "Epoch 1/500\n",
      "22/22 [==============================] - 11s 489ms/step - loss: 0.0457 - accuracy: 0.8356 - dice_coef: 0.9134 - val_loss: 0.0151 - val_accuracy: 0.9872 - val_dice_coef: 0.5430\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 10s 445ms/step - loss: 0.0135 - accuracy: 0.9969 - dice_coef: 0.9959 - val_loss: 0.0131 - val_accuracy: 0.9998 - val_dice_coef: 0.5076\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0101 - accuracy: 0.9923 - dice_coef: 0.9951 - val_loss: 0.0113 - val_accuracy: 0.9987 - val_dice_coef: 0.5055\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0088 - accuracy: 0.9927 - dice_coef: 0.9956 - val_loss: 0.0068 - val_accuracy: 0.9856 - val_dice_coef: 0.5119\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0082 - accuracy: 0.9927 - dice_coef: 0.9957 - val_loss: 0.0069 - val_accuracy: 0.9923 - val_dice_coef: 0.5085\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0076 - accuracy: 0.9928 - dice_coef: 0.9959 - val_loss: 0.0055 - val_accuracy: 0.9847 - val_dice_coef: 0.5104\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0071 - accuracy: 0.9929 - dice_coef: 0.9959 - val_loss: 0.0081 - val_accuracy: 0.9965 - val_dice_coef: 0.5052\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0066 - accuracy: 0.9932 - dice_coef: 0.9961 - val_loss: 0.0060 - val_accuracy: 0.9924 - val_dice_coef: 0.5070\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0062 - accuracy: 0.9931 - dice_coef: 0.9961 - val_loss: 0.0060 - val_accuracy: 0.9932 - val_dice_coef: 0.5066\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0060 - accuracy: 0.9932 - dice_coef: 0.9962 - val_loss: 0.0043 - val_accuracy: 0.9824 - val_dice_coef: 0.5099\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0058 - accuracy: 0.9931 - dice_coef: 0.9962 - val_loss: 0.0045 - val_accuracy: 0.9874 - val_dice_coef: 0.5094\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0055 - accuracy: 0.9933 - dice_coef: 0.9963 - val_loss: 0.0104 - val_accuracy: 0.9983 - val_dice_coef: 0.5036\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0053 - accuracy: 0.9933 - dice_coef: 0.9963 - val_loss: 0.0049 - val_accuracy: 0.9907 - val_dice_coef: 0.5063\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0051 - accuracy: 0.9932 - dice_coef: 0.9963 - val_loss: 0.0042 - val_accuracy: 0.9886 - val_dice_coef: 0.5079\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0049 - accuracy: 0.9932 - dice_coef: 0.9963 - val_loss: 0.0051 - val_accuracy: 0.9939 - val_dice_coef: 0.5059\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0047 - accuracy: 0.9934 - dice_coef: 0.9964 - val_loss: 0.0039 - val_accuracy: 0.9878 - val_dice_coef: 0.5070\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0046 - accuracy: 0.9933 - dice_coef: 0.9964 - val_loss: 0.0059 - val_accuracy: 0.9952 - val_dice_coef: 0.5049\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0045 - accuracy: 0.9933 - dice_coef: 0.9964 - val_loss: 0.0039 - val_accuracy: 0.9888 - val_dice_coef: 0.5065\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0044 - accuracy: 0.9933 - dice_coef: 0.9963 - val_loss: 0.0072 - val_accuracy: 0.9972 - val_dice_coef: 0.5043\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0043 - accuracy: 0.9934 - dice_coef: 0.9964 - val_loss: 0.0060 - val_accuracy: 0.9967 - val_dice_coef: 0.5048\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0043 - accuracy: 0.9932 - dice_coef: 0.9963 - val_loss: 0.0032 - val_accuracy: 0.9849 - val_dice_coef: 0.5074\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0041 - accuracy: 0.9935 - dice_coef: 0.9965 - val_loss: 0.0055 - val_accuracy: 0.9945 - val_dice_coef: 0.5045\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0040 - accuracy: 0.9933 - dice_coef: 0.9964 - val_loss: 0.0046 - val_accuracy: 0.9947 - val_dice_coef: 0.5053\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0039 - accuracy: 0.9934 - dice_coef: 0.9965 - val_loss: 0.0039 - val_accuracy: 0.9923 - val_dice_coef: 0.5060\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0038 - accuracy: 0.9934 - dice_coef: 0.9965 - val_loss: 0.0044 - val_accuracy: 0.9929 - val_dice_coef: 0.5053\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0038 - accuracy: 0.9934 - dice_coef: 0.9965 - val_loss: 0.0046 - val_accuracy: 0.9942 - val_dice_coef: 0.5049\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0037 - accuracy: 0.9936 - dice_coef: 0.9965 - val_loss: 0.0032 - val_accuracy: 0.9887 - val_dice_coef: 0.5064\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0037 - accuracy: 0.9935 - dice_coef: 0.9965 - val_loss: 0.0036 - val_accuracy: 0.9916 - val_dice_coef: 0.5059\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0036 - accuracy: 0.9935 - dice_coef: 0.9965 - val_loss: 0.0040 - val_accuracy: 0.9933 - val_dice_coef: 0.5056\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0035 - accuracy: 0.9935 - dice_coef: 0.9965 - val_loss: 0.0033 - val_accuracy: 0.9903 - val_dice_coef: 0.5059\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0035 - accuracy: 0.9935 - dice_coef: 0.9965 - val_loss: 0.0039 - val_accuracy: 0.9930 - val_dice_coef: 0.5057\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0035 - accuracy: 0.9935 - dice_coef: 0.9965 - val_loss: 0.0033 - val_accuracy: 0.9905 - val_dice_coef: 0.5064\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0034 - accuracy: 0.9934 - dice_coef: 0.9965 - val_loss: 0.0032 - val_accuracy: 0.9906 - val_dice_coef: 0.5062\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0034 - accuracy: 0.9937 - dice_coef: 0.9966 - val_loss: 0.0035 - val_accuracy: 0.9923 - val_dice_coef: 0.5055\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0033 - accuracy: 0.9935 - dice_coef: 0.9966 - val_loss: 0.0034 - val_accuracy: 0.9913 - val_dice_coef: 0.5057\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0032 - accuracy: 0.9937 - dice_coef: 0.9966 - val_loss: 0.0040 - val_accuracy: 0.9936 - val_dice_coef: 0.5047\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0033 - accuracy: 0.9936 - dice_coef: 0.9966 - val_loss: 0.0032 - val_accuracy: 0.9908 - val_dice_coef: 0.5055\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0033 - accuracy: 0.9936 - dice_coef: 0.9966 - val_loss: 0.0037 - val_accuracy: 0.9930 - val_dice_coef: 0.5050\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0032 - accuracy: 0.9936 - dice_coef: 0.9966 - val_loss: 0.0031 - val_accuracy: 0.9898 - val_dice_coef: 0.5055\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0031 - accuracy: 0.9937 - dice_coef: 0.9967 - val_loss: 0.0031 - val_accuracy: 0.9897 - val_dice_coef: 0.5055\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0031 - accuracy: 0.9936 - dice_coef: 0.9966 - val_loss: 0.0045 - val_accuracy: 0.9941 - val_dice_coef: 0.5045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0031 - accuracy: 0.9936 - dice_coef: 0.9966 - val_loss: 0.0032 - val_accuracy: 0.9920 - val_dice_coef: 0.5052\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0030 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0026 - val_accuracy: 0.9887 - val_dice_coef: 0.5061\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0030 - accuracy: 0.9937 - dice_coef: 0.9966 - val_loss: 0.0030 - val_accuracy: 0.9903 - val_dice_coef: 0.5055\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0030 - accuracy: 0.9937 - dice_coef: 0.9966 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5056\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0030 - accuracy: 0.9937 - dice_coef: 0.9967 - val_loss: 0.0029 - val_accuracy: 0.9901 - val_dice_coef: 0.5055\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0029 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0030 - val_accuracy: 0.9905 - val_dice_coef: 0.5054\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0029 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0038 - val_accuracy: 0.9933 - val_dice_coef: 0.5048\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0029 - accuracy: 0.9937 - dice_coef: 0.9967 - val_loss: 0.0031 - val_accuracy: 0.9919 - val_dice_coef: 0.5050\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0029 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0030 - val_accuracy: 0.9904 - val_dice_coef: 0.5053\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0030 - accuracy: 0.9935 - dice_coef: 0.9966 - val_loss: 0.0028 - val_accuracy: 0.9900 - val_dice_coef: 0.5055\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0028 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5057\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0028 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0026 - val_accuracy: 0.9890 - val_dice_coef: 0.5059\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0028 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0031 - val_accuracy: 0.9921 - val_dice_coef: 0.5054\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0028 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5051\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0028 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0030 - val_accuracy: 0.9910 - val_dice_coef: 0.5055\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0028 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0035 - val_accuracy: 0.9931 - val_dice_coef: 0.5047\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0028 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0025 - val_accuracy: 0.9882 - val_dice_coef: 0.5062\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0028 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0030 - val_accuracy: 0.9911 - val_dice_coef: 0.5051\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0028 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0024 - val_accuracy: 0.9878 - val_dice_coef: 0.5059\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0028 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0022 - val_accuracy: 0.9857 - val_dice_coef: 0.5073\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0027 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0037 - val_accuracy: 0.9938 - val_dice_coef: 0.5047\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0027 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9913 - val_dice_coef: 0.5049\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0028 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0019 - val_accuracy: 0.9805 - val_dice_coef: 0.5081\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0028 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0033 - val_accuracy: 0.9926 - val_dice_coef: 0.5046\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0027 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9927 - val_dice_coef: 0.5051\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0027 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0026 - val_accuracy: 0.9897 - val_dice_coef: 0.5057\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0027 - accuracy: 0.9938 - dice_coef: 0.9968 - val_loss: 0.0030 - val_accuracy: 0.9912 - val_dice_coef: 0.5052\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0027 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0026 - val_accuracy: 0.9898 - val_dice_coef: 0.5053\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0027 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0033 - val_accuracy: 0.9929 - val_dice_coef: 0.5046\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0027 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0032 - val_accuracy: 0.9926 - val_dice_coef: 0.5050\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0027 - accuracy: 0.9938 - dice_coef: 0.9967 - val_loss: 0.0035 - val_accuracy: 0.9929 - val_dice_coef: 0.5046\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0027 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0033 - val_accuracy: 0.9927 - val_dice_coef: 0.5047\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0027 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5055\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0026 - accuracy: 0.9939 - dice_coef: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9915 - val_dice_coef: 0.5049\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0026 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0023 - val_accuracy: 0.9874 - val_dice_coef: 0.5058\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5051\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5052\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0026 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5054\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5052\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9969 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5058\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0026 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9906 - val_dice_coef: 0.5057\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0026 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5053\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9969 - val_loss: 0.0033 - val_accuracy: 0.9926 - val_dice_coef: 0.5049\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9969 - val_loss: 0.0031 - val_accuracy: 0.9928 - val_dice_coef: 0.5050\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0026 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5052\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0026 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0025 - val_accuracy: 0.9893 - val_dice_coef: 0.5052\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0024 - val_accuracy: 0.9887 - val_dice_coef: 0.5057\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 10s 454ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0024 - val_accuracy: 0.9891 - val_dice_coef: 0.5056\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0032 - val_accuracy: 0.9924 - val_dice_coef: 0.5047\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9899 - val_dice_coef: 0.5052\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0022 - val_accuracy: 0.9859 - val_dice_coef: 0.5060\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0026 - val_accuracy: 0.9898 - val_dice_coef: 0.5053\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0023 - val_accuracy: 0.9879 - val_dice_coef: 0.5056\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0026 - accuracy: 0.9940 - dice_coef: 0.9968 - val_loss: 0.0022 - val_accuracy: 0.9876 - val_dice_coef: 0.5060\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0025 - val_accuracy: 0.9887 - val_dice_coef: 0.5052\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0026 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0032 - val_accuracy: 0.9925 - val_dice_coef: 0.5047\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0029 - val_accuracy: 0.9923 - val_dice_coef: 0.5050\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5051\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0026 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0031 - val_accuracy: 0.9923 - val_dice_coef: 0.5047\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0040 - val_accuracy: 0.9938 - val_dice_coef: 0.5043\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5050\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5050\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0032 - val_accuracy: 0.9924 - val_dice_coef: 0.5047\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5053\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9905 - val_dice_coef: 0.5055\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5055\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0028 - val_accuracy: 0.9901 - val_dice_coef: 0.5050\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0030 - val_accuracy: 0.9926 - val_dice_coef: 0.5048\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0025 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9916 - val_dice_coef: 0.5049\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0033 - val_accuracy: 0.9935 - val_dice_coef: 0.5047\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5047\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5050\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0025 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9913 - val_dice_coef: 0.5048\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0023 - val_accuracy: 0.9882 - val_dice_coef: 0.5056\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0023 - val_accuracy: 0.9884 - val_dice_coef: 0.5057\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0029 - val_accuracy: 0.9916 - val_dice_coef: 0.5049\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0034 - val_accuracy: 0.9931 - val_dice_coef: 0.5045\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9899 - val_dice_coef: 0.5054\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0025 - accuracy: 0.9941 - dice_coef: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9903 - val_dice_coef: 0.5052\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5051\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9896 - val_dice_coef: 0.5056\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5051\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5052\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5049\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5050\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9896 - val_dice_coef: 0.5056\n",
      "Epoch 128/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0034 - val_accuracy: 0.9926 - val_dice_coef: 0.5044\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5049\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5053\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9899 - val_dice_coef: 0.5052\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0035 - val_accuracy: 0.9934 - val_dice_coef: 0.5046\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0025 - val_accuracy: 0.9901 - val_dice_coef: 0.5057\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5052\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9890 - val_dice_coef: 0.5052\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5056\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0025 - accuracy: 0.9942 - dice_coef: 0.9969 - val_loss: 0.0030 - val_accuracy: 0.9922 - val_dice_coef: 0.5049\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5050\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9908 - val_dice_coef: 0.5048\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0024 - accuracy: 0.9942 - dice_coef: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9905 - val_dice_coef: 0.5048\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0025 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9894 - val_dice_coef: 0.5051\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0033 - val_accuracy: 0.9930 - val_dice_coef: 0.5045\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9916 - val_dice_coef: 0.5046\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0030 - val_accuracy: 0.9918 - val_dice_coef: 0.5048\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5047\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5049\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0030 - val_accuracy: 0.9911 - val_dice_coef: 0.5046\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0022 - val_accuracy: 0.9876 - val_dice_coef: 0.5058\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0023 - val_accuracy: 0.9881 - val_dice_coef: 0.5055\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5048\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0023 - val_accuracy: 0.9891 - val_dice_coef: 0.5057\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9911 - val_dice_coef: 0.5049\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9899 - val_dice_coef: 0.5050\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0033 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9924 - val_dice_coef: 0.5045\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5050\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9887 - val_dice_coef: 0.5054\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5045\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9911 - val_dice_coef: 0.5048\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5047\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0032 - val_accuracy: 0.9927 - val_dice_coef: 0.5044\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9906 - val_dice_coef: 0.5048\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5048\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5053\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9906 - val_dice_coef: 0.5052\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9925 - val_dice_coef: 0.5045\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9914 - val_dice_coef: 0.5047\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9893 - val_dice_coef: 0.5054\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9923 - val_dice_coef: 0.5046\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0023 - val_accuracy: 0.9879 - val_dice_coef: 0.5056\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5050\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9891 - val_dice_coef: 0.5051\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9905 - val_dice_coef: 0.5050\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5050\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9889 - val_dice_coef: 0.5052\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9911 - val_dice_coef: 0.5047\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5051\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9898 - val_dice_coef: 0.5048\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9900 - val_dice_coef: 0.5051\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9893 - val_dice_coef: 0.5053\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9921 - val_dice_coef: 0.5047\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5050\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9898 - val_dice_coef: 0.5049\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5051\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5048\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5051\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9899 - val_dice_coef: 0.5051\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5051\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9903 - val_dice_coef: 0.5050\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9901 - val_dice_coef: 0.5049\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9924 - val_dice_coef: 0.5046\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9904 - val_dice_coef: 0.5048\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9910 - val_dice_coef: 0.5051\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 10s 454ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5048\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5047\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9918 - val_dice_coef: 0.5045\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0023 - val_accuracy: 0.9882 - val_dice_coef: 0.5057\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9905 - val_dice_coef: 0.5051\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9890 - val_dice_coef: 0.5051\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5051\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0024 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5048\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9896 - val_dice_coef: 0.5048\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9891 - val_dice_coef: 0.5053\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5048\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9919 - val_dice_coef: 0.5045\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0024 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5048\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0023 - val_accuracy: 0.9878 - val_dice_coef: 0.5053\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9898 - val_dice_coef: 0.5053\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9899 - val_dice_coef: 0.5050\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9901 - val_dice_coef: 0.5049\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9914 - val_dice_coef: 0.5047\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9912 - val_dice_coef: 0.5046\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5047\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0032 - val_accuracy: 0.9921 - val_dice_coef: 0.5043\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5047\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9920 - val_dice_coef: 0.5047\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5048\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9903 - val_dice_coef: 0.5049\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5045\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0032 - val_accuracy: 0.9923 - val_dice_coef: 0.5044\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9915 - val_dice_coef: 0.5047\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9917 - val_dice_coef: 0.5044\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5046\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0023 - val_accuracy: 0.9884 - val_dice_coef: 0.5055\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9905 - val_dice_coef: 0.5048\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9898 - val_dice_coef: 0.5050\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9943 - dice_coef: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9928 - val_dice_coef: 0.5043\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9911 - val_dice_coef: 0.5047\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5047\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9895 - val_dice_coef: 0.5050\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9917 - val_dice_coef: 0.5046\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9922 - val_dice_coef: 0.5045\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9914 - val_dice_coef: 0.5046\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0023 - val_accuracy: 0.9886 - val_dice_coef: 0.5052\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5047\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9914 - val_dice_coef: 0.5046\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5050\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9914 - val_dice_coef: 0.5044\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9900 - val_dice_coef: 0.5050\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5050\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9915 - val_dice_coef: 0.5046\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9905 - val_dice_coef: 0.5046\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9927 - val_dice_coef: 0.5045\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9892 - val_dice_coef: 0.5051\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9913 - val_dice_coef: 0.5045\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5045\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9913 - val_dice_coef: 0.5046\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9890 - val_dice_coef: 0.5050\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5050\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9916 - val_dice_coef: 0.5045\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5045\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9919 - val_dice_coef: 0.5045\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9917 - val_dice_coef: 0.5048\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9896 - val_dice_coef: 0.5048\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9911 - val_dice_coef: 0.5047\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9921 - val_dice_coef: 0.5045\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9895 - val_dice_coef: 0.5048\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5046\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9921 - val_dice_coef: 0.5044\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9915 - val_dice_coef: 0.5045\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9913 - val_dice_coef: 0.5044\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5047\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9896 - val_dice_coef: 0.5051\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9915 - val_dice_coef: 0.5046\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9901 - val_dice_coef: 0.5048\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9909 - val_dice_coef: 0.5046\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9916 - val_dice_coef: 0.5047\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9906 - val_dice_coef: 0.5048\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9897 - val_dice_coef: 0.5049\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9913 - val_dice_coef: 0.5047\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9906 - val_dice_coef: 0.5047\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9914 - val_dice_coef: 0.5043\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0032 - val_accuracy: 0.9928 - val_dice_coef: 0.5044\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9909 - val_dice_coef: 0.5046\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5049\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5046\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5045\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5047\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9910 - val_dice_coef: 0.5047\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5046\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9912 - val_dice_coef: 0.5046\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0028 - val_accuracy: 0.9917 - val_dice_coef: 0.5046\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9906 - val_dice_coef: 0.5046\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9905 - val_dice_coef: 0.5048\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5048\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9922 - val_dice_coef: 0.5044\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5047\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9914 - val_dice_coef: 0.5043\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9907 - val_dice_coef: 0.5047\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9901 - val_dice_coef: 0.5049\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5046\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9897 - val_dice_coef: 0.5050\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0025 - val_accuracy: 0.9899 - val_dice_coef: 0.5048\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9910 - val_dice_coef: 0.5044\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9914 - val_dice_coef: 0.5044\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5045\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 10s 459ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9926 - val_dice_coef: 0.5043\n",
      "Epoch 300/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0026 - val_accuracy: 0.9895 - val_dice_coef: 0.5050\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9896 - val_dice_coef: 0.5047\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 10s 458ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9971 - val_loss: 0.0032 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5047\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5046\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9911 - val_dice_coef: 0.5048\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9897 - val_dice_coef: 0.5050\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5046\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0024 - val_accuracy: 0.9888 - val_dice_coef: 0.5050\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9913 - val_dice_coef: 0.5046\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9904 - val_dice_coef: 0.5050\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0022 - val_accuracy: 0.9873 - val_dice_coef: 0.5055\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9906 - val_dice_coef: 0.5046\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0033 - val_accuracy: 0.9917 - val_dice_coef: 0.5043\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5045\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5047\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0023 - accuracy: 0.9944 - dice_coef: 0.9971 - val_loss: 0.0034 - val_accuracy: 0.9926 - val_dice_coef: 0.5042\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0023 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9914 - val_dice_coef: 0.5044\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9891 - val_dice_coef: 0.5052\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9901 - val_dice_coef: 0.5048\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9909 - val_dice_coef: 0.5046\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5043\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5046\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5049\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9906 - val_dice_coef: 0.5049\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9917 - val_dice_coef: 0.5045\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9910 - val_dice_coef: 0.5046\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9971 - val_loss: 0.0024 - val_accuracy: 0.9896 - val_dice_coef: 0.5054\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5045\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5048\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9921 - val_dice_coef: 0.5045\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9917 - val_dice_coef: 0.5044\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0024 - val_accuracy: 0.9890 - val_dice_coef: 0.5053\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5046\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9914 - val_dice_coef: 0.5047\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9900 - val_dice_coef: 0.5048\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9927 - val_dice_coef: 0.5043\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9904 - val_dice_coef: 0.5047\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9913 - val_dice_coef: 0.5046\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9916 - val_dice_coef: 0.5043\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5046\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9895 - val_dice_coef: 0.5049\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9911 - val_dice_coef: 0.5044\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9912 - val_dice_coef: 0.5046\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9907 - val_dice_coef: 0.5046\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5047\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9904 - val_dice_coef: 0.5048\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 10s 462ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9915 - val_dice_coef: 0.5048\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9925 - val_dice_coef: 0.5042\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9904 - val_dice_coef: 0.5048\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9926 - val_dice_coef: 0.5044\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5044\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9904 - val_dice_coef: 0.5047\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9921 - val_dice_coef: 0.5044\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5047\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9917 - val_dice_coef: 0.5045\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5044\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9900 - val_dice_coef: 0.5048\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9945 - dice_coef: 0.9972 - val_loss: 0.0023 - val_accuracy: 0.9891 - val_dice_coef: 0.5053\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9897 - val_dice_coef: 0.5050\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5046\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0037 - val_accuracy: 0.9930 - val_dice_coef: 0.5041\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9905 - val_dice_coef: 0.5045\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9901 - val_dice_coef: 0.5045\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9921 - val_dice_coef: 0.5042\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5046\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9900 - val_dice_coef: 0.5047\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9915 - val_dice_coef: 0.5044\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5047\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9895 - val_dice_coef: 0.5050\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9911 - val_dice_coef: 0.5047\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9909 - val_dice_coef: 0.5046\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5046\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5045\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9904 - val_dice_coef: 0.5048\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9906 - val_dice_coef: 0.5046\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5043\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9910 - val_dice_coef: 0.5044\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9921 - val_dice_coef: 0.5044\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0033 - val_accuracy: 0.9924 - val_dice_coef: 0.5042\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9890 - val_dice_coef: 0.5049\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5046\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0024 - val_accuracy: 0.9891 - val_dice_coef: 0.5049\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5046\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0023 - val_accuracy: 0.9884 - val_dice_coef: 0.5051\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9916 - val_dice_coef: 0.5042\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9903 - val_dice_coef: 0.5045\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9908 - val_dice_coef: 0.5043\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0026 - val_accuracy: 0.9896 - val_dice_coef: 0.5046\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5048\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9911 - val_dice_coef: 0.5046\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5045\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5047\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9897 - val_dice_coef: 0.5047\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0024 - val_accuracy: 0.9892 - val_dice_coef: 0.5051\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5043\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9921 - val_dice_coef: 0.5044\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9919 - val_dice_coef: 0.5044\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9898 - val_dice_coef: 0.5048\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5046\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0025 - val_accuracy: 0.9896 - val_dice_coef: 0.5048\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9918 - val_dice_coef: 0.5043\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9901 - val_dice_coef: 0.5048\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5043\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9904 - val_dice_coef: 0.5044\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9915 - val_dice_coef: 0.5043\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0033 - val_accuracy: 0.9916 - val_dice_coef: 0.5041\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9923 - val_dice_coef: 0.5045\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9920 - val_dice_coef: 0.5045\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5046\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 11s 479ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9908 - val_dice_coef: 0.5045\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0022 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0026 - val_accuracy: 0.9903 - val_dice_coef: 0.5047\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0033 - val_accuracy: 0.9920 - val_dice_coef: 0.5043\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9900 - val_dice_coef: 0.5047\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9900 - val_dice_coef: 0.5048\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0026 - val_accuracy: 0.9897 - val_dice_coef: 0.5048\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0034 - val_accuracy: 0.9927 - val_dice_coef: 0.5041\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9906 - val_dice_coef: 0.5046\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9914 - val_dice_coef: 0.5044\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5045\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5045\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5046\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9906 - val_dice_coef: 0.5046\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9913 - val_dice_coef: 0.5044\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0021 - accuracy: 0.9949 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9913 - val_dice_coef: 0.5044\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9909 - val_dice_coef: 0.5045\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9920 - val_dice_coef: 0.5044\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0032 - val_accuracy: 0.9920 - val_dice_coef: 0.5042\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0033 - val_accuracy: 0.9919 - val_dice_coef: 0.5042\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0033 - val_accuracy: 0.9921 - val_dice_coef: 0.5043\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9921 - val_dice_coef: 0.5043\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5043\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5046\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5046\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5047\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9915 - val_dice_coef: 0.5044\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9905 - val_dice_coef: 0.5044\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0032 - val_accuracy: 0.9923 - val_dice_coef: 0.5043\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0025 - val_accuracy: 0.9888 - val_dice_coef: 0.5049\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 10s 477ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5044\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0025 - val_accuracy: 0.9895 - val_dice_coef: 0.5049\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9905 - val_dice_coef: 0.5047\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5044\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9913 - val_dice_coef: 0.5043\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9898 - val_dice_coef: 0.5046\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9920 - val_dice_coef: 0.5043\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0022 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0024 - val_accuracy: 0.9886 - val_dice_coef: 0.5050\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9895 - val_dice_coef: 0.5048\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0032 - val_accuracy: 0.9921 - val_dice_coef: 0.5043\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5045\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5044\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9905 - val_dice_coef: 0.5047\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9910 - val_dice_coef: 0.5047\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9911 - val_dice_coef: 0.5043\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9892 - val_dice_coef: 0.5047\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 10s 477ms/step - loss: 0.0021 - accuracy: 0.9946 - dice_coef: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9891 - val_dice_coef: 0.5049\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9901 - val_dice_coef: 0.5047\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9909 - val_dice_coef: 0.5045\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0026 - val_accuracy: 0.9898 - val_dice_coef: 0.5048\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9915 - val_dice_coef: 0.5042\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9906 - val_dice_coef: 0.5044\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9905 - val_dice_coef: 0.5045\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9972 - val_loss: 0.0035 - val_accuracy: 0.9930 - val_dice_coef: 0.5043\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5047\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 10s 477ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9919 - val_dice_coef: 0.5043\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9949 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9908 - val_dice_coef: 0.5045\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9918 - val_dice_coef: 0.5043\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9918 - val_dice_coef: 0.5044\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 10s 477ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9917 - val_dice_coef: 0.5043\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 10s 467ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5044\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0033 - val_accuracy: 0.9919 - val_dice_coef: 0.5041\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9903 - val_dice_coef: 0.5046\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0026 - val_accuracy: 0.9902 - val_dice_coef: 0.5046\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0025 - val_accuracy: 0.9894 - val_dice_coef: 0.5049\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9917 - val_dice_coef: 0.5043\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9920 - val_dice_coef: 0.5045\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9913 - val_dice_coef: 0.5045\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9949 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9916 - val_dice_coef: 0.5043\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0033 - val_accuracy: 0.9921 - val_dice_coef: 0.5043\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9902 - val_dice_coef: 0.5047\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 11s 481ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9906 - val_dice_coef: 0.5045\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0031 - val_accuracy: 0.9915 - val_dice_coef: 0.5044\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0033 - val_accuracy: 0.9928 - val_dice_coef: 0.5041\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9904 - val_dice_coef: 0.5046\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 10s 466ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9906 - val_dice_coef: 0.5044\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 10s 477ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0034 - val_accuracy: 0.9926 - val_dice_coef: 0.5041\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0027 - val_accuracy: 0.9900 - val_dice_coef: 0.5047\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9949 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 11s 480ms/step - loss: 0.0021 - accuracy: 0.9949 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9907 - val_dice_coef: 0.5046\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 10s 471ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9910 - val_dice_coef: 0.5045\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 10s 472ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9912 - val_dice_coef: 0.5045\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 10s 475ms/step - loss: 0.0021 - accuracy: 0.9948 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9916 - val_dice_coef: 0.5045\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 10s 476ms/step - loss: 0.0021 - accuracy: 0.9949 - dice_coef: 0.9973 - val_loss: 0.0028 - val_accuracy: 0.9911 - val_dice_coef: 0.5045\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.0021 - accuracy: 0.9947 - dice_coef: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9914 - val_dice_coef: 0.5044\n",
      "\n",
      "Metrics at the end of training\n",
      "  val_accuracy:       0.9913949966430664\n",
      "  val loss:      0.002975321845715289\n",
      "  val_dice:      0.5043593049049377\n",
      "  Training time: 1:25:25.008993\n",
      "\n",
      "Total round time:  1:25:37.150380\n",
      "\n",
      "\n",
      "Total training time:   1:25:39.104550\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    \n",
    "    #already did 0-6\n",
    "    if(i<7):\n",
    "        continue\n",
    "    \n",
    "    Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0, ultrasound_arrays[0].shape[1], ultrasound_arrays[0].shape[2], ultrasound_arrays[0].shape[3]])\n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0, ultrasound_arrays[0].shape[1], ultrasound_arrays[0].shape[2], ultrasound_arrays[0].shape[3]])\n",
    "    \n",
    "    val_ultrasound_data = ultrasound_arrays[i]\n",
    "    val_segmentation_data = segmentation_arrays[i]\n",
    "    val_ultrasound_filename = training_ultrasound_filenames[i]\n",
    "    \n",
    "    for train_index in range(n_files):\n",
    "        if train_index != i:\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data, ultrasound_arrays[train_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data, segmentation_arrays[train_index]))\n",
    "    \n",
    "    n_train = train_ultrasound_data.shape[0]\n",
    "    n_val = val_ultrasound_data.shape[0]\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(i))\n",
    "    print(\"\\nTraining on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.sagittal_spine_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "        loss=[unet.weighted_categorical_crossentropy(WCE_weights)],\n",
    "        metrics=[\"accuracy\", unet.dice_coef]\n",
    "        # metrics=[\"accuracy\"]\n",
    "    )\n",
    "        \n",
    "    #model.summary()\n",
    "        \n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size),\n",
    "        max_shift_factor=max_shift_factor,\n",
    "        min_zoom_factor=min_zoom_factor,\n",
    "        max_zoom_factor=max_zoom_factor,\n",
    "        max_rotation_angle=max_rotation_angle\n",
    "    )\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    training_log = model.fit_generator(\n",
    "        training_generator,\n",
    "        validation_data=(val_ultrasound_data, val_segmentation_data),\n",
    "        epochs=num_epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "        \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"\\nMetrics at the end of training\")\n",
    "#     print(training_log.history)\n",
    "    print(\"  val_accuracy:       {}\".format(training_log.history['val_accuracy'][-1]))\n",
    "    print(\"  val loss:      {}\".format(training_log.history['val_loss'][-1]))\n",
    "    print(\"  val_dice:      {}\".format(training_log.history['val_dice_coef'][-1]))\n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # Plot training loss and metrics\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "    axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "    axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "    axes[0].legend(['Training loss', 'Validation loss'])\n",
    "    \n",
    "    axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "    axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "    axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "    axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    y_pred_val  = model.predict(val_ultrasound_data)\n",
    "    \n",
    "    # Saving predictions for further evaluation\n",
    "    \n",
    "    filename_noext, extension = os.path.splitext(val_ultrasound_filename)\n",
    "    val_prediction_filename = save_timestamp + \"_prediction_\" + filename_noext + \".npy\"\n",
    "    val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "    np.save(val_prediction_fullname, y_pred_val)\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(i) + \"_\" + save_timestamp + \".h5\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    model.save(model_fullname)\n",
    "    \n",
    "    # Validation results\n",
    "     \n",
    "    vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "        roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "    val_fuzzy_metrics[i] = evaluation_metrics.compute_evaluation_metrics(\n",
    "        y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "    val_best_metrics[i]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "    val_aurocs[i]          = vali_area\n",
    "    val_best_thresholds[i] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6b0d5164b670>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mval_aurocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mval_best_thresholds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mval_best_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevaluation_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRUE_POSITIVE_RATE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mval_best_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevaluation_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFALSE_POSITIVE_RATE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mval_best_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevaluation_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRECALL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "\n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    results_df.loc[i] = [\n",
    "        val_aurocs[i],\n",
    "        val_best_thresholds[i],\n",
    "        val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "        val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "        val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "        val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "        val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "        val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "        val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "    ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "\n",
    "csv_filename = this_notebook_name + \"_\" + save_timestamp + \".csv\"\n",
    "csv_fullname = os.path.join(results_save_fullpath, csv_filename)\n",
    "results_df.to_csv(csv_fullname)\n",
    "\n",
    "print(\"Results saved to: {}\".format(csv_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "\n",
    "num_vali = val_ultrasound_data.shape[0]\n",
    "num_show = 5\n",
    "\n",
    "indices = [i for i in range(num_vali)]\n",
    "sample_indices = sample(indices, num_show)\n",
    "\n",
    "# Uncomment for comparing the same images\n",
    "sample_indices = [105, 195, 391, 133, 142]\n",
    "\n",
    "fig = plt.figure(figsize=(18, num_show*5))\n",
    "for i in range(num_show):\n",
    "    a0 = fig.add_subplot(num_show,3,i*3+1)\n",
    "    img0 = a0.imshow(np.flipud(val_ultrasound_data[sample_indices[i], :, :, 0].astype(np.float32)))\n",
    "    a0.set_title(\"Ultrasound #{}\".format(sample_indices[i]))\n",
    "    a1 = fig.add_subplot(num_show,3,i*3+2)\n",
    "    img1 = a1.imshow(np.flipud(val_segmentation_data[sample_indices[i], :, :, 0]), vmin=0.0, vmax=1.0)\n",
    "    a1.set_title(\"Segmentation #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img1, fraction=0.046, pad=0.04)\n",
    "    a2 = fig.add_subplot(num_show,3,i*3+3)\n",
    "    img2 = a2.imshow(np.flipud(y_pred_val[sample_indices[i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "    a2.set_title(\"Prediction #{}\".format(sample_indices[i]))\n",
    "    c = fig.colorbar(img2, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
