{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import sample\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_unet import UNet\n",
    "from dataset_loader import DataAugmentor\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2021-08-05_12-41-47\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"PyTorchSagittalSpineSegmentationStudy\"\n",
    "\n",
    "# Update this folder name for your computer\n",
    "\n",
    "local_data_folder = r\"/home/nick/dev/SaggitalSpineSegmentation_Data\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500 # was 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.025\n",
    "min_learning_rate = 0.00005\n",
    "\n",
    "# I will use exponential learning rate decay, not linear\n",
    "# need to solve the system of equations:\n",
    "\n",
    "# x**y = max_learning_rate\n",
    "# x**(num_epochs + y) = min_learning_rate\n",
    "\n",
    "# Here, x is the decay factor we want\n",
    "# solving analytically by hand bc I am a math major (and sympy failed):\n",
    "\n",
    "# y*ln(x) = ln(max_learning_rate)\n",
    "# (num_epochs + y) * ln(x) = ln(min_learning_rate)\n",
    "# (num_epochs + (ln(max_learning_rate)/ln(x)))*ln(x) = ln(min_learning_rate)\n",
    "# ln(x)*num_epochs + ln(max_learning_rate) = ln(min_learning_rate)\n",
    "# ln(x) = (ln(min_learning_rate) - ln(max_learning_rate))/num_epochs\n",
    "# ln(x) = ln( (min_learning_rate / max_learning_rate)**(1/num_epochs) )\n",
    "# x = (min_learning_rate / max_learning_rate)**(1/num_epochs)\n",
    "\n",
    "learning_rate_decay = (min_learning_rate / max_learning_rate)**(1/num_epochs)\n",
    "\n",
    "regularization_rate = 0.001\n",
    "filter_multiplier = 10\n",
    "WCE_weights = np.array([0.1, 0.9])\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "limit_validation_rounds = -1\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "\n",
    "# roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01]\n",
    "# limit_validation_rounds = 1\n",
    "# num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what data to download\n",
    "\n",
    "girder_api_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "training_ultrasound_ids = [\n",
    "    \"5da9e5c0d9e6a3be02d012b4\",\n",
    "    \"5da9e5c7d9e6a3be02d012c6\",\n",
    "    \"5da9e5c2d9e6a3be02d012b7\",\n",
    "    \"5da9e5c3d9e6a3be02d012ba\",\n",
    "    \"5da9e5c8d9e6a3be02d012c9\",\n",
    "    \"5da9e5c5d9e6a3be02d012c0\",\n",
    "    \"5da9e5c6d9e6a3be02d012c3\",\n",
    "    \"5da9e5c4d9e6a3be02d012bd\"\n",
    "]\n",
    "\n",
    "training_ultrasound_filenames = [\n",
    "    \"q000_ultrasound.npy\",\n",
    "    \"q001_ultrasound.npy\",\n",
    "    \"q002_ultrasound.npy\",\n",
    "    \"q003_ultrasound.npy\",\n",
    "    \"q004_ultrasound.npy\",\n",
    "    \"q005_ultrasound.npy\",\n",
    "    \"q006_ultrasound.npy\",\n",
    "    \"q007_ultrasound.npy\"\n",
    "]\n",
    "\n",
    "training_segmentation_ids = [\n",
    "    \"5da9e5c8d9e6a3be02d012cc\",\n",
    "    \"5da9e5ccd9e6a3be02d012de\",\n",
    "    \"5da9e5c9d9e6a3be02d012cf\",\n",
    "    \"5da9e5cad9e6a3be02d012d2\",\n",
    "    \"5da9e5cdd9e6a3be02d012e1\",\n",
    "    \"5da9e5cbd9e6a3be02d012d8\",\n",
    "    \"5da9e5cbd9e6a3be02d012db\",\n",
    "    \"5da9e5cad9e6a3be02d012d5\"\n",
    "]\n",
    "\n",
    "training_segmentation_filenames = [\n",
    "    \"q000_segmentation.npy\",\n",
    "    \"q001_segmentation.npy\",\n",
    "    \"q002_segmentation.npy\",\n",
    "    \"q003_segmentation.npy\",\n",
    "    \"q004_segmentation.npy\",\n",
    "    \"q005_segmentation.npy\",\n",
    "    \"q006_segmentation.npy\",\n",
    "    \"q007_segmentation.npy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These subfolders will be created/populated in the data folder\n",
    "\n",
    "data_arrays_folder    = \"DataArrays\"\n",
    "notebooks_save_folder = \"SavedNotebooks\"\n",
    "results_save_folder   = \"SavedResults\"\n",
    "models_save_folder    = \"SavedModels\"\n",
    "val_data_folder       = \"PredictionsValidation\"\n",
    "\n",
    "data_arrays_fullpath = os.path.join(local_data_folder, data_arrays_folder)\n",
    "notebooks_save_fullpath = os.path.join(local_data_folder, notebooks_save_folder)\n",
    "results_save_fullpath = os.path.join(local_data_folder, results_save_folder)\n",
    "models_save_fullpath = os.path.join(local_data_folder, models_save_folder)\n",
    "val_data_fullpath = os.path.join(local_data_folder, val_data_folder)\n",
    "\n",
    "if not os.path.exists(data_arrays_fullpath):\n",
    "    os.makedirs(data_arrays_fullpath)\n",
    "    print(\"Created folder: {}\".format(data_arrays_fullpath))\n",
    "\n",
    "if not os.path.exists(notebooks_save_fullpath):\n",
    "    os.makedirs(notebooks_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(notebooks_save_fullpath))\n",
    "\n",
    "if not os.path.exists(results_save_fullpath):\n",
    "    os.makedirs(results_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(results_save_fullpath))\n",
    "\n",
    "if not os.path.exists(models_save_fullpath):\n",
    "    os.makedirs(models_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(models_save_fullpath))\n",
    "\n",
    "if not os.path.exists(val_data_fullpath):\n",
    "    os.makedirs(val_data_fullpath)\n",
    "    print(\"Created folder: {}\".format(val_data_fullpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training files ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014389efa80c4cbc96022db693151d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total download time: 0:00:00.013084\n"
     ]
    }
   ],
   "source": [
    "# Download data from Girder\n",
    "\n",
    "time_download_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Downloading training files ...\")\n",
    "\n",
    "# Setting up number of validation rounds\n",
    "\n",
    "n_files = len(training_ultrasound_ids)\n",
    "if limit_validation_rounds > 0:\n",
    "    num_validation_rounds = min(n_files, limit_validation_rounds)\n",
    "else:\n",
    "    num_validation_rounds = n_files\n",
    "\n",
    "# Preparing progress bar\n",
    "\n",
    "f = IntProgress(min=0, max=n_files*2)\n",
    "display(f)\n",
    "\n",
    "# Downloading files\n",
    "\n",
    "gclient = girder_client.GirderClient(apiUrl=girder_api_url)\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    if not os.path.exists(ultrasound_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(ultrasound_fullname))\n",
    "        gclient.downloadFile(training_ultrasound_ids[i], ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "    if not os.path.exists(segmentation_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(segmentation_fullname))\n",
    "        gclient.downloadFile(training_segmentation_ids[i], segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "\n",
    "time_download_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal download time: {}\".format(time_download_stop - time_download_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59220b658ccc42bc87034a2c5fedbb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time to load from files: 0:00:00.142763\n"
     ]
    }
   ],
   "source": [
    "# Read data into torch tensors in channel-first format, dtype float\n",
    "\n",
    "ultrasound_tensors = []\n",
    "segmentation_tensors = []\n",
    "\n",
    "f = IntProgress(min=0, max=n_files * 2)\n",
    "display(f)\n",
    "\n",
    "time_start = datetime.datetime.now()\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "\n",
    "    ultrasound_data = np.load(ultrasound_fullname)\n",
    "    ultrasound_data = torch.Tensor(ultrasound_data).permute(0,3,1,2).float()\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_data = np.load(segmentation_fullname)\n",
    "    segmentation_data = torch.Tensor(segmentation_data).long().permute(0,3,1,2)\n",
    "\n",
    "    f.value = i * 2 + 2\n",
    "    \n",
    "    ultrasound_tensors.append(ultrasound_data)\n",
    "    segmentation_tensors.append(segmentation_data)\n",
    "\n",
    "time_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal time to load from files: {}\".format(time_stop - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Use cuda GPU if available\n",
    "\n",
    "device_name = \" \"\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "else:\n",
    "    device_name = 'CPU'\n",
    "    \n",
    "print('Using device:', device_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2021-08-05_12-41-47\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    500\n",
      "Step size maximum:   0.025\n",
      "Step size decay:     0.9876477074806245\n",
      "Batch size:          128\n",
      "Regularization rate: 0.001\n",
      "\n",
      "Saving validation predictions in: /home/nick/dev/SaggitalSpineSegmentation_Data/PredictionsValidation\n",
      "Saving models in:                 /home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels\n",
      "\n",
      "*** Leave-one-out round # 0\n",
      "\n",
      "Training on 2767 images, validating on 523 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8048fc86278443e889ae5c439100d8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.035754946247455496\n",
      "  val_dice:      0.9916396379470825\n",
      "  Training time: 0:22:39.487038\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy_model-0_2021-08-05_12-41-47.msd\n",
      "\n",
      "Total round time:  0:22:39.672552\n",
      "\n",
      "\n",
      "Total training time:   0:22:43.589504\n"
     ]
    }
   ],
   "source": [
    "# This is where all the training gets done\n",
    "\n",
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Initialize metrics\n",
    "\n",
    "train_loss = 0.0\n",
    "val_loss = 0.0\n",
    "val_dice = 0.0\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    \n",
    "    f = IntProgress(min=0, max=num_epochs)\n",
    "     \n",
    "    # Set Up TensorBoard\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "#   Prepare data arrays\n",
    "#   leave out ultrasound_arrays[i]\n",
    "    \n",
    "    train_ultrasound_data = torch.zeros(\n",
    "        [0, ultrasound_tensors[0].shape[1], ultrasound_tensors[0].shape[2], ultrasound_tensors[0].shape[3]]).float()\n",
    "    train_segmentation_data = torch.zeros(\n",
    "        [0, ultrasound_tensors[0].shape[1], ultrasound_tensors[0].shape[2], ultrasound_tensors[0].shape[3]]).long()\n",
    "    \n",
    "    val_ultrasound_data = ultrasound_tensors[i]\n",
    "    val_segmentation_data = segmentation_tensors[i]\n",
    "    val_ultrasound_filename = training_ultrasound_filenames[i]\n",
    "    \n",
    "    for train_index in range(n_files):\n",
    "        if train_index != i:\n",
    "            train_ultrasound_data = torch.cat((train_ultrasound_data, ultrasound_tensors[train_index]))\n",
    "            train_segmentation_data = torch.cat((train_segmentation_data, segmentation_tensors[train_index]))\n",
    "    \n",
    "    n_train = train_ultrasound_data.size(0)\n",
    "    n_val = val_ultrasound_data.size(0)\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(i))\n",
    "    print(\"\\nTraining on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    display(f)\n",
    "    \n",
    "    # Create and train model\n",
    "\n",
    "    model = UNet(128,num_classes).to(device).train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=max_learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optim, gamma=learning_rate_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(WCE_weights).float()).to(device)\n",
    "    dice_metric = torchmetrics.F1(num_classes=num_classes, mdmc_average='global').to(device).eval()\n",
    "    softmax = torch.nn.Softmax(dim=1).to(device)\n",
    "    \n",
    "    # PyTorch Datasets and DataLoaders\n",
    "    \n",
    "    training_dataset = DataAugmentor(train_ultrasound_data,\n",
    "                                     train_segmentation_data,\n",
    "                                     image_dimensions=(ultrasound_size, ultrasound_size),\n",
    "                                     max_rotation_angle=max_rotation_angle,\n",
    "                                     max_shift_factor=max_shift_factor,\n",
    "                                     min_zoom_factor=min_zoom_factor,\n",
    "                                     max_zoom_factor=max_zoom_factor)\n",
    "    training_generator = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    val_dataset = DataAugmentor(val_ultrasound_data,\n",
    "                                val_segmentation_data,\n",
    "                                image_dimensions=(ultrasound_size, ultrasound_size),\n",
    "                                max_rotation_angle=max_rotation_angle,\n",
    "                                max_shift_factor=max_shift_factor,\n",
    "                                min_zoom_factor=min_zoom_factor,\n",
    "                                max_zoom_factor=max_zoom_factor)\n",
    "    val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    # training loop for this validation split\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        \n",
    "        # training\n",
    "        model.train()\n",
    "        num = 0\n",
    "        for batch, target in training_generator:\n",
    "            num += 1\n",
    "            optim.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "            pred = model(batch).to(device)\n",
    "            loss = criterion(pred, target.squeeze(1))\n",
    "            loss += regularization_rate * sum(x.abs().sum()for k, x in model.named_parameters() if k.endswith('conv.bias')) * 1e-5\n",
    "            loss.backward()\n",
    "            train_loss += loss.item() * batch.size(0)\n",
    "            optim.step()\n",
    "            \n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        train_loss = train_loss / training_dataset.__len__()\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        num = 0\n",
    "        for batch, target in val_generator:\n",
    "            num += 1\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "            pred = model(batch).to(device)\n",
    "            loss = criterion(pred, target.squeeze(1))\n",
    "            val_loss += loss.item() * batch.size(0)\n",
    "            pred_probmap = softmax(pred)\n",
    "            dice = dice_metric(pred_probmap, target)\n",
    "            val_dice += dice.item()\n",
    "        \n",
    "        if epoch==1:\n",
    "            writer.add_graph(model, batch)\n",
    "            \n",
    "        val_loss = val_loss / val_dataset.__len__()\n",
    "        val_dice = val_dice / num\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "        writer.add_scalar('Dice/validation', val_dice, epoch)\n",
    "        writer.add_scalar('Meta/learning_rate', lr_scheduler.get_last_lr()[-1], epoch)\n",
    "        \n",
    "        f.value = epoch\n",
    "        \n",
    "\n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Print training log\n",
    "    \n",
    "    print(\"\\nMetrics at the end of training\")\n",
    "    print(\"  val loss:      {}\".format(val_loss))\n",
    "    print(\"  val_dice:      {}\".format(val_dice))\n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # TODO Plot training loss and metrics\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    y_pred_val  = model(val_ultrasound_data.to(device))\n",
    "    \n",
    "    # Saving predictions for further evaluation\n",
    "    \n",
    "    filename_noext, extension = os.path.splitext(val_ultrasound_filename)\n",
    "    val_prediction_filename = save_timestamp + \"_prediction_\" + filename_noext + \".npy\"\n",
    "    val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "    torch.save(y_pred_val, val_prediction_fullname)\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(i) + \"_\" + save_timestamp + \".msd\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    print(model_fullname)\n",
    "    torch.save(model.state_dict(), model_fullname)\n",
    "    \n",
    "    # Validation results\n",
    "     \n",
    "#     vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "#         roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "#     val_fuzzy_metrics[i] = evaluation_metrics.compute_evaluation_metrics(\n",
    "#         y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "#     val_best_metrics[i]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "#     val_aurocs[i]          = vali_area\n",
    "#     val_best_thresholds[i] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "    \n",
    "    # just do one validation split\n",
    "    break\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require([\"base/js/namespace\"],function(Jupyter) {\n",
       "    Jupyter.notebook.save_checkpoint();\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved to: /home/nick/dev/SaggitalSpineSegmentation_Data/SavedNotebooks/PyTorchSagittalSpineSegmentationStudy_2021-08-05_12-41-47.html\n"
     ]
    }
   ],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([523, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sm = torch.nn.functional.softmax(y_pred_val, dim=1)\n",
    "pred_sm = pred_sm[:,1,:,:]\n",
    "pred_sm.size()\n",
    "# torch.nn.functional.softmax(y_pred_val, dim=1)[:,1,:,:].to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sm_np = np.array(pred_sm.to('cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_np = torch.squeeze(val_segmentation_data, dim=1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = int(523*np.random.rand())\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(20,15)\n",
    "axs[0].imshow(gt_np[index])\n",
    "axs[1].imshow(pred_sm_np[index])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
