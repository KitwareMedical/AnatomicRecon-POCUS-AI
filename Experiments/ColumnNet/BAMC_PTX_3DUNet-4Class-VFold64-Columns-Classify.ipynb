{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2108fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureChannelFirst,\n",
    "    EnsureType,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandSpatialCrop,\n",
    "    RandZoom,\n",
    "    ScaleIntensityRange,\n",
    "    SpatialCrop,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import site\n",
    "site.addsitedir('../../ARGUS')\n",
    "from ARGUSUtils_Transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd296a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "img1_dir = \"../../Data/VFoldData/ColumnData/\"\n",
    "\n",
    "all_images = sorted(glob(os.path.join(img1_dir, '*_Class?_*.mha')))\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "num_workers_tr = 8\n",
    "batch_size_tr = 8\n",
    "num_workers_va = 8\n",
    "batch_size_va = 2\n",
    "\n",
    "model_filename_base = \"BAMC_PTX_3DUNet-4Class.best_model.vfold64-Columns-Class\"\n",
    "\n",
    "num_images = len(all_images)\n",
    "print(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c16aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 12 1\n",
      "65 1 15\n",
      "62 15 4\n",
      "67 4 10\n",
      "69 10 2\n",
      "68 2 11\n",
      "63 11 7\n",
      "63 7 11\n",
      "62 11 8\n",
      "61 8 12\n"
     ]
    }
   ],
   "source": [
    "ns_prefix = ['025ns','026ns','027ns','035ns','048ns','055ns','117ns',\n",
    "             '135ns','193ns','210ns','215ns','218ns','219ns','221ns','247ns']\n",
    "s_prefix = ['004s','019s','030s','034s','037s','043s','065s','081s',\n",
    "            '206s','208s','211s','212s','224s','228s','236s','237s']\n",
    "\n",
    "fold_prefix_list = []\n",
    "ns_count = 0\n",
    "s_count = 0\n",
    "for i in range(num_folds):\n",
    "    if i%2 == 0:\n",
    "        num_ns = 2\n",
    "        num_s = 1\n",
    "        if i > num_folds-3:\n",
    "            num_s = 2\n",
    "    else:\n",
    "        num_ns = 1\n",
    "        num_s = 2\n",
    "    f = []\n",
    "    for ns in range(num_ns):\n",
    "        f.append([ns_prefix[ns_count+ns]])\n",
    "    ns_count += num_ns\n",
    "    for s in range(num_s):\n",
    "        f.append([s_prefix[s_count+s]])\n",
    "    s_count += num_s\n",
    "    fold_prefix_list.append(f)\n",
    "        \n",
    "train_files = []\n",
    "train_classes = []\n",
    "val_files = []\n",
    "val_classes = []\n",
    "test_files = []\n",
    "test_classes = []\n",
    "\n",
    "for i in range(num_folds):\n",
    "    tr_folds = []\n",
    "    for f in range(i,i+num_folds-2):\n",
    "        tr_folds.append(fold_prefix_list[f%num_folds])\n",
    "    tr_folds = list(np.concatenate(tr_folds).flat)\n",
    "    va_folds = list(np.concatenate(fold_prefix_list[(i+num_folds-2) % num_folds]).flat)\n",
    "    te_folds = list(np.concatenate(fold_prefix_list[(i+num_folds-1) % num_folds]).flat)\n",
    "\n",
    "    train_files.append([im for im in all_images if any(pref in im for pref in tr_folds)])\n",
    "    fold_classes = []\n",
    "    for file in train_files[len(train_files)-1]:\n",
    "        if 'ClassN' in file:\n",
    "            fold_classes.append([0])\n",
    "        elif 'ClassR' in file:\n",
    "            fold_classes.append([1])\n",
    "        elif 'ClassS' in file:\n",
    "            fold_classes.append([2])\n",
    "        else:\n",
    "            print(\"Error: Class tag not found in validation file\", file)\n",
    "    train_classes.append(fold_classes)\n",
    "\n",
    "    val_files.append([im for im in all_images if any(pref in im for pref in va_folds)])\n",
    "    fold_classes = []\n",
    "    for file in val_files[len(val_files)-1]:\n",
    "        if 'ClassN' in file:\n",
    "            fold_classes.append([0])\n",
    "        elif 'ClassR' in file:\n",
    "            fold_classes.append([1])\n",
    "        elif 'ClassS' in file:\n",
    "            fold_classes.append([2])\n",
    "        else:\n",
    "            print(\"Error: Class tag not found in validation file\", file)\n",
    "    val_classes.append(fold_classes)\n",
    "\n",
    "    test_files.append([im for im in all_images if any(pref in im for pref in te_folds)])\n",
    "    fold_classes = []\n",
    "    for file in test_files[len(test_files)-1]:\n",
    "        if 'ClassN' in file:\n",
    "            fold_classes.append([0])\n",
    "        elif 'ClassR' in file:\n",
    "            fold_classes.append([1])\n",
    "        elif 'ClassS' in file:\n",
    "            fold_classes.append([2])\n",
    "        else:\n",
    "            print(\"Error: Class tag not found in validation file\", file)\n",
    "    test_classes.append(fold_classes)\n",
    "\n",
    "    print(len(train_files[i]),len(val_files[i]),len(test_files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(),\n",
    "        AddChannel(),\n",
    "        ScaleIntensityRange(\n",
    "            a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=48,\n",
    "            axis=2),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=8,\n",
    "            axis=0,\n",
    "            require_labeled=True),\n",
    "        RandFlip(\n",
    "            prob=0.5, \n",
    "            spatial_axis=2),\n",
    "        RandFlip(\n",
    "            prob=0.5, \n",
    "            spatial_axis=0),\n",
    "        RandZoom(\n",
    "            prob=0.5, \n",
    "            min_zoom=1.0,\n",
    "            max_zoom=1.2,\n",
    "            keep_size=True,\n",
    "            mode='trilinear'),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(),\n",
    "        AddChannel(),\n",
    "        ScaleIntensityRange(\n",
    "            a_min=0, a_max=255,\n",
    "            b_min=0.0, b_max=1.0),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=48,\n",
    "            axis=2),\n",
    "        ARGUS_RandSpatialCropSlices(\n",
    "            num_slices=8,\n",
    "            axis=0,\n",
    "            require_labeled=True),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=True, num_classes=num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa31a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n",
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "class ColumnDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "print(str(num_folds), len(train_files), len(train_classes))\n",
    "train_ds = [ColumnDataset(train_files[i], train_classes[i], transforms=train_transforms)\n",
    "                for i in range(num_folds)]\n",
    "train_loader = [torch.utils.data.DataLoader(train_ds[i], batch_size=batch_size_tr, shuffle=True)\n",
    "                for i in range(num_folds)]\n",
    "\n",
    "print(str(num_folds), len(val_files), len(val_classes))\n",
    "val_ds = [ColumnDataset(val_files[i], val_classes[i], transforms=val_transforms)\n",
    "                for i in range(num_folds)]\n",
    "val_loader = [torch.utils.data.DataLoader(val_ds[i], batch_size=batch_size_va, shuffle=True)\n",
    "                for i in range(num_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43e72763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5edcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vfold_train(vfold_num, train_loader, val_loader):\n",
    "    model = DenseNet121(spatial_dims=3, in_channels=1,\n",
    "                    out_channels=num_classes).to(device)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "    auc_metric = ROCAUCMetric()\n",
    "\n",
    "    max_epochs = 1000\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    \n",
    "    root_dir = \".\"\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"{vfold_num}: epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = (\n",
    "                batch_data[0].to(device),\n",
    "                batch_data[1].to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(\n",
    "                f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "                f\"train_loss: {loss.item():.4f}\")\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"{vfold_num} epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "                y = torch.tensor([], dtype=torch.long, device=device)\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = (\n",
    "                        val_data[0].to(device),\n",
    "                        val_data[1].to(device),\n",
    "                    )\n",
    "                    y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                    y = torch.cat([y, val_labels], dim=0)\n",
    "                y_onehot = [y_trans(i) for i in decollate_batch(y)]\n",
    "                y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "                auc_metric(y_pred_act, y_onehot)\n",
    "                result = auc_metric.aggregate()\n",
    "                auc_metric.reset()\n",
    "                del y_pred_act, y_onehot\n",
    "                metric_values.append(result)\n",
    "                acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "                acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "                if result > best_metric:\n",
    "                    best_metric = result\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(\n",
    "                        root_dir, model_filename_base+'_'+str(vfold_num)+'.pth'))\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                    f\" current accuracy: {acc_metric:.4f}\"\n",
    "                    f\" best AUC: {best_metric:.4f}\"\n",
    "                    f\" at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "\n",
    "    np.save(model_filename_base+\"_loss_\"+str(vfold_num)+\".npy\", epoch_loss_values)\n",
    "    np.save(model_filename_base+\"_acc_\"+str(vfold_num)+\".npy\", metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12667a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "0: epoch 1/3000\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_folds):\n",
    "    vfold_train(i, train_loader[i], val_loader[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
