{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dc7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Lambda,\n",
    "    Resize,\n",
    "    ScaleIntensityRange,\n",
    "    SpatialCrop,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import monai.utils as utils\n",
    "\n",
    "import torch\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import mode\n",
    "\n",
    "import ffmpeg\n",
    "import av\n",
    "\n",
    "import itk\n",
    "from itk import TubeTK as ttk\n",
    "\n",
    "from time import perf_counter\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from ARGUSUtils import *\n",
    "from ARGUSUtils_IO import *\n",
    "from ARGUSUtils_Linearization import *\n",
    "from ARGUSUtils_Transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebe5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Data/Final15/BAMC-PTXNoSliding/Do_Not_Use/219ns_image_1895283541879_clean.mov\"\n",
    "#filename = \"../Data/Final15/BAMC-PTXSliding/212s_image_128692595484031_CLEAN.mov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d75768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Load Time: is 0.47677268367260695\n",
      "   Resampling with zoom = 1.2627627627627627\n",
      "Time for Linearization Time: is 3.8460789481177926\n"
     ]
    }
   ],
   "source": [
    "height,width = shape_video(filename)\n",
    "\n",
    "with time_this(\"Load Time:\"):\n",
    "    vid = load_video(filename,height,width)\n",
    "with time_this(\"Linearization Time:\"):\n",
    "    vid_linear = linearize_video(vid).transpose([2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74614ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "num_classes = 3\n",
    "class_pleura = 1\n",
    "class_rib = 2\n",
    "\n",
    "net_in_dims = 3\n",
    "net_in_channels = 1\n",
    "net_channels=(16, 32, 64, 128, 32)\n",
    "net_strides=(2, 2, 2, 2)\n",
    "        \n",
    "num_slices = 48\n",
    "size_x = 320\n",
    "size_y = 320\n",
    "roi_size = (size_x,size_y,num_slices)\n",
    "\n",
    "vfold_num = 0\n",
    "model_filename_base = \"./Models/BAMC_PTX_ARUNET-3D-PR-Final15/\"\n",
    "model_type = \"best\"  #\"best\" or \"last\"\n",
    "model_file = model_filename_base+model_type+'_model.vfold_'+str(vfold_num)+'.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0b243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale = ScaleIntensityRange(\n",
    "    a_min=0, a_max=255,\n",
    "    b_min=0.0, b_max=1.0)\n",
    "vid_linear_scaled = Scale.__call__(vid_linear)\n",
    "Crop = ARGUS_RandSpatialCropSlices(\n",
    "    num_slices=num_slices,\n",
    "    center_slice=30,\n",
    "    axis=2)\n",
    "image_data = np.empty([1, 1, vid_linear.shape[0], vid_linear.shape[1], num_slices])\n",
    "image_data[0, 0] = Crop.__call__(vid_linear_scaled)\n",
    "image_data_t = ToTensor().__call__(image_data.astype(np.float32))\n",
    "itk.imwrite(itk.GetImageFromArray(image_data[0,0].astype(np.float32)), \"ARUNet_input_image.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4d1854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numObjects = 3\n",
      "largest = 1\n",
      "Time for CPU 3D Inference Time: is 7.290886126924306\n"
     ]
    }
   ],
   "source": [
    "output_image = vid_linear\n",
    "\n",
    "pleura_prior = 1\n",
    "min_size_comp = 110000\n",
    "max_size_comp = 160000\n",
    "\n",
    "with time_this(\"CPU 3D Inference Time:\"):\n",
    "    model = UNet(\n",
    "        dimensions=net_in_dims,\n",
    "        in_channels=net_in_channels,\n",
    "        out_channels=num_classes,\n",
    "        channels=net_channels,\n",
    "        strides=net_strides,\n",
    "        num_res_units=2,\n",
    "        norm=Norm.BATCH,\n",
    "    ).to(device)    \n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = sliding_window_inference(\n",
    "            image_data_t.to(device), roi_size, 1, model)\n",
    "        prob_shape = test_outputs[0,:,:,:,:].shape\n",
    "        prob = np.empty(prob_shape)\n",
    "        for c in range(num_classes):\n",
    "            itkProb = itk.GetImageFromArray(test_outputs[0,c,:,:,:].cpu())\n",
    "            imMathProb = ttk.ImageMath.New(itkProb)\n",
    "            imMathProb.Blur(5)\n",
    "            itkProb = imMathProb.GetOutput()\n",
    "            prob[c] = itk.GetArrayFromImage(itkProb)\n",
    "        arrc1 = np.zeros(prob[0].shape)\n",
    "        pmin = prob[0].min()\n",
    "        pmax = prob[0].max()\n",
    "        for c in range(1,num_classes):\n",
    "            pmin = min(pmin, prob[c].min())\n",
    "            pmax = max(pmax, prob[c].max())\n",
    "        prange = pmax - pmin\n",
    "        prob = (prob - pmin) / prange\n",
    "        prob[class_pleura] = prob[class_pleura] * pleura_prior\n",
    "        done = False\n",
    "        while not done:\n",
    "            done = True\n",
    "            count = np.count_nonzero(arrc1>0)\n",
    "            prior_factor = 1\n",
    "            while count<min_size_comp:\n",
    "                prior_factor *= 1.05\n",
    "                prob[class_pleura] = prob[class_pleura] * 1.05\n",
    "                prob[class_rib] = prob[class_rib] * 1.05\n",
    "                arrc1 = np.argmax(prob,axis=0)\n",
    "                count = np.count_nonzero(arrc1>0)\n",
    "                done = False\n",
    "            while count>max_size_comp:\n",
    "                prior_factor *= 0.95\n",
    "                prob[class_pleura] = prob[class_pleura] * 0.95\n",
    "                prob[class_rib] = prob[class_rib] * 0.95\n",
    "                arrc1 = np.argmax(prob,axis=0)\n",
    "                count = np.count_nonzero(arrc1>0)\n",
    "                done = False\n",
    "\n",
    "        arrcF = np.where(arrc1==1,1,0)\n",
    "        itkcF = itk.GetImageFromArray(arrcF.astype(np.float32))\n",
    "        imMathCF = ttk.ImageMath.New(itkcF)\n",
    "        imMathCF.Erode(5,class_pleura,0)\n",
    "        imMathCF.Dilate(5,class_pleura,0)\n",
    "        output_image = imMathCF.GetOutputUChar()\n",
    "        \n",
    "        itkSegmentConnectedComponents = itk.itkARGUS.SegmentConnectedComponents\n",
    "        seg = itkSegmentConnectedComponents.New(Input=output_image)\n",
    "        seg.SetKeepOnlyLargestComponent(True)\n",
    "        seg.Update()\n",
    "\n",
    "        output_image = seg.GetOutput()\n",
    "        output_arr = itk.GetArrayFromImage(output_image)\n",
    "\n",
    "itk.imwrite(output_image, \"ARUNet_output_image.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498ff385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 - 210\n",
      "Time for CPU ROI Extraction Time: is 0.003480011597275734\n",
      "(48, 160, 320)\n"
     ]
    }
   ],
   "source": [
    "with time_this(\"CPU ROI Extraction Time:\"):\n",
    "    ROI_min_x = 0\n",
    "    ROI_max_x = output_arr.shape[0]-1\n",
    "    while( np.count_nonzero(output_arr[ROI_min_x,:,:]==1)==0 and ROI_min_x<ROI_max_x ):\n",
    "        ROI_min_x += 1\n",
    "    while( np.count_nonzero(output_arr[ROI_max_x,:,:]==1)==0 and ROI_max_x>ROI_min_x):\n",
    "        ROI_max_x -= 1\n",
    "    ROI_mid_x = (ROI_min_x + ROI_max_x)//2\n",
    "    ROI_min_x = max(ROI_mid_x-80,0)\n",
    "    ROI_max_x = min(ROI_min_x+160,output_arr.shape[0]-1)\n",
    "    ROI_min_x = ROI_max_x-160\n",
    "    ROI_arr = output_arr[ROI_min_x:ROI_max_x,:,:].transpose([2,0,1])\n",
    "    print(ROI_min_x, \"-\", ROI_max_x)\n",
    "\n",
    "print(ROI_arr.shape)\n",
    "ROI_image = itk.GetImageFromArray(ROI_arr)\n",
    "itk.imwrite(ROI_image, \"ROI_input_image.mha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56aa1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_num_classes = 3\n",
    "ROI_class_not_sliding = 1\n",
    "ROI_class_sliding = 2\n",
    "\n",
    "ROI_class_prior = [1.3,1.0,0.85]\n",
    "\n",
    "ROI_net_in_dims = 2\n",
    "ROI_net_in_channels = 4\n",
    "ROI_net_channels=(32, 64, 128)\n",
    "ROI_net_strides=(2, 2)\n",
    "\n",
    "ROI_num_slices = 32\n",
    "ROI_size_x = 160\n",
    "ROI_size_y = 320\n",
    "ROI_roi_size = (ROI_size_x, ROI_size_y)\n",
    "\n",
    "ROI_vfold_num = 0\n",
    "ROI_model_filename_base = \"./Models/BAMC_PTX_ROINet-StdDevExtended-ExtrudedNS-Final15/\"\n",
    "ROI_model_type = \"best\"  #\"best\" or \"last\"\n",
    "ROI_model_file = model_filename_base+model_type+'_model.vfold_'+str(vfold_num)+'.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24de397",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale = ScaleIntensityRange(\n",
    "    a_min=0, a_max=255,\n",
    "    b_min=0.0, b_max=1.0)\n",
    "ROI_arr_scaled = Scale.__call__(ROI_arr)\n",
    "\n",
    "Crop = ARGUS_RandSpatialCropSlices(\n",
    "    num_slices=ROI_num_slices,\n",
    "    axis=0,\n",
    "    reduce_to_statistics=True,\n",
    "    extended=True)\n",
    "ROI_arr_data = np.empty([1, ROI_net_in_channels, ROI_arr.shape[1], ROI_arr.shape[2]])\n",
    "ROI_arr_data[0] = Crop.__call__(ROI_arr_scaled)\n",
    "ROI_arr_data_t = ToTensor().__call__(ROI_arr_data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d496235",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"model.1.submodule.1.submodule.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.residual.weight\", \"model.1.submodule.1.submodule.residual.bias\". \n\tUnexpected key(s) in state_dict: \"model.1.submodule.1.submodule.0.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.0.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.0.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.0.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.0.residual.weight\", \"model.1.submodule.1.submodule.0.residual.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.0.residual.weight\", \"model.1.submodule.1.submodule.1.submodule.0.residual.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.residual.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.residual.bias\", \"model.1.submodule.1.submodule.1.submodule.2.0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.2.0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.2.0.conv.weight\", \"model.1.submodule.1.submodule.2.0.conv.bias\", \"model.1.submodule.1.submodule.2.0.adn.N.weight\", \"model.1.submodule.1.submodule.2.0.adn.N.bias\", \"model.1.submodule.1.submodule.2.0.adn.N.running_mean\", \"model.1.submodule.1.submodule.2.0.adn.N.running_var\", \"model.1.submodule.1.submodule.2.0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.2.0.adn.A.weight\", \"model.1.submodule.1.submodule.2.1.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.2.1.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.A.weight\". \n\tsize mismatch for model.0.conv.unit0.conv.weight: copying a param with shape torch.Size([16, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 4, 3, 3]).\n\tsize mismatch for model.0.conv.unit0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.conv.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.0.conv.unit1.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.residual.weight: copying a param with shape torch.Size([16, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 4, 3, 3]).\n\tsize mismatch for model.0.residual.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.conv.weight: copying a param with shape torch.Size([32, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.residual.weight: copying a param with shape torch.Size([32, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.0.residual.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.2.0.conv.weight: copying a param with shape torch.Size([64, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.2.0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.conv.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.2.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n\tsize mismatch for model.2.1.conv.unit0.conv.weight: copying a param with shape torch.Size([3, 3, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2289659/559993484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ).to(device)    \n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mROI_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROI_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mROI_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"model.1.submodule.1.submodule.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.residual.weight\", \"model.1.submodule.1.submodule.residual.bias\". \n\tUnexpected key(s) in state_dict: \"model.1.submodule.1.submodule.0.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.0.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.0.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.0.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.0.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.0.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.0.residual.weight\", \"model.1.submodule.1.submodule.0.residual.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.0.residual.weight\", \"model.1.submodule.1.submodule.1.submodule.0.residual.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.conv.unit1.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.residual.weight\", \"model.1.submodule.1.submodule.1.submodule.1.submodule.residual.bias\", \"model.1.submodule.1.submodule.1.submodule.2.0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.2.0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.2.0.adn.A.weight\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.1.submodule.2.1.conv.unit0.adn.A.weight\", \"model.1.submodule.1.submodule.2.0.conv.weight\", \"model.1.submodule.1.submodule.2.0.conv.bias\", \"model.1.submodule.1.submodule.2.0.adn.N.weight\", \"model.1.submodule.1.submodule.2.0.adn.N.bias\", \"model.1.submodule.1.submodule.2.0.adn.N.running_mean\", \"model.1.submodule.1.submodule.2.0.adn.N.running_var\", \"model.1.submodule.1.submodule.2.0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.2.0.adn.A.weight\", \"model.1.submodule.1.submodule.2.1.conv.unit0.conv.weight\", \"model.1.submodule.1.submodule.2.1.conv.unit0.conv.bias\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.weight\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.bias\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_mean\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.running_var\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.N.num_batches_tracked\", \"model.1.submodule.1.submodule.2.1.conv.unit0.adn.A.weight\". \n\tsize mismatch for model.0.conv.unit0.conv.weight: copying a param with shape torch.Size([16, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 4, 3, 3]).\n\tsize mismatch for model.0.conv.unit0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit0.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.conv.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.0.conv.unit1.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.conv.unit1.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.0.residual.weight: copying a param with shape torch.Size([16, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 4, 3, 3]).\n\tsize mismatch for model.0.residual.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.conv.weight: copying a param with shape torch.Size([32, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit0.adn.N.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.conv.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.conv.unit1.adn.N.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.0.residual.weight: copying a param with shape torch.Size([32, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.0.residual.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for model.1.submodule.2.0.conv.weight: copying a param with shape torch.Size([64, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.2.0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.0.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.conv.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.conv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.1.submodule.2.1.conv.unit0.adn.N.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for model.2.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n\tsize mismatch for model.2.1.conv.unit0.conv.weight: copying a param with shape torch.Size([3, 3, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 3])."
     ]
    }
   ],
   "source": [
    "with time_this(\"ROI Inference Time:\"):\n",
    "    ROI_model = UNet(\n",
    "        dimensions=ROI_net_in_dims,\n",
    "        in_channels=ROI_net_in_channels,\n",
    "        out_channels=ROI_num_classes,\n",
    "        channels=ROI_net_channels,\n",
    "        strides=ROI_net_strides,\n",
    "        num_res_units=2,\n",
    "        norm=Norm.BATCH,\n",
    "    ).to(device)    \n",
    "    ROI_model.load_state_dict(torch.load(ROI_model_file))\n",
    "    ROI_model.eval()\n",
    "    with torch.no_grad():\n",
    "        ROI_test_outputs = sliding_window_inference(\n",
    "            ROI_arr_data_t.to(device), ROI_roi_size, 1, ROI_model)\n",
    "        val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "        ROI_prob_shape = ROI_test_outputs[0,:,:,:].shape\n",
    "        ROI_prob = np.empty(ROI_prob_shape)\n",
    "        for c in range(ROI_num_classes):\n",
    "            ROI_itkProb = itk.GetImageFromArray(ROI_test_outputs[0,c,:,:].cpu())\n",
    "            ROI_imMathProb = ttk.ImageMath.New(ROI_itkProb)\n",
    "            ROI_imMathProb.Blur(5)\n",
    "            ROI_itkProb = ROI_imMathProb.GetOutput()\n",
    "            itk.imwrite(ROI_itkProb, \"prob\"+str(c)+\".mha\")\n",
    "            ROI_prob[c] = itk.GetArrayFromImage(ROI_itkProb)\n",
    "        ROI_arrc1 = np.zeros(ROI_prob[0].shape)\n",
    "        ROI_pmin = ROI_prob[0].min()\n",
    "        ROI_pmax = ROI_prob[0].max()\n",
    "        for c in range(1,ROI_num_classes):\n",
    "            ROI_pmin = min(ROI_pmin, ROI_prob[c].min())\n",
    "            ROI_pmax = max(ROI_pmax, ROI_prob[c].max())\n",
    "        ROI_prange = ROI_pmax - ROI_pmin\n",
    "        ROI_prob = (ROI_prob - ROI_pmin) / ROI_prange\n",
    "        for c in range(ROI_num_classes):\n",
    "            ROI_prob[c] = ROI_prob[c] * ROI_class_prior[c]\n",
    "        ROI_arrc1 = np.argmax(ROI_prob,axis=0)\n",
    "        \n",
    "        ROI_itkc1 = itk.GetImageFromArray(ROI_arrc1.astype(np.float32))\n",
    "        ROI_imMathC1 = ttk.ImageMath.New(ROI_itkc1)\n",
    "        for c in range(ROI_num_classes):\n",
    "            ROI_imMathC1.Erode(5,c,0)\n",
    "            ROI_imMathC1.Dilate(5,c,0)\n",
    "        ROI_itkc1 = ROI_imMathC1.GetOutputUChar()\n",
    "        ROI_arrc1 = itk.GetArrayFromImage(ROI_itkc1)\n",
    "        ROI_class_not_sliding_count = np.count_nonzero(ROI_arrc1==ROI_class_not_sliding)\n",
    "        ROI_class_sliding_count = np.count_nonzero(ROI_arrc1==ROI_class_sliding)\n",
    "        if( ROI_class_not_sliding_count > ROI_class_sliding_count ):\n",
    "            print(\"Not Sliding:\", ROI_class_not_sliding_count, \">\", ROI_class_sliding_count)\n",
    "        else:\n",
    "            print(\"Sliding:\", ROI_class_not_sliding_count, \"<\", ROI_class_sliding_count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642c044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
